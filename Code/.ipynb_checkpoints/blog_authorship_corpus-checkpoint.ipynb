{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shrea\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shrea\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing the NLP libraries\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import xml.etree.ElementTree as et\n",
    "from xml.sax.saxutils import escape, unescape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11253.male.26.Technology.Aquarius.xml',\n",
       " '11762.female.25.Student.Aries.xml',\n",
       " '15365.female.34.indUnk.Cancer.xml',\n",
       " '17944.female.39.indUnk.Sagittarius.xml',\n",
       " '21828.male.40.Internet.Cancer.xml',\n",
       " '23166.female.25.indUnk.Virgo.xml',\n",
       " '23191.female.23.Advertising.Taurus.xml',\n",
       " '23676.male.33.Technology.Scorpio.xml',\n",
       " '24336.male.24.Technology.Leo.xml',\n",
       " '5114.male.25.indUnk.Scorpio.xml',\n",
       " '7596.male.26.Internet.Scorpio.xml',\n",
       " '8173.male.42.indUnk.Capricorn.xml',\n",
       " '8349.male.24.Consulting.Cancer.xml',\n",
       " '9289.male.23.Marketing.Taurus.xml',\n",
       " '9470.male.25.Communications-Media.Aries.xml']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./Dataset/The Blog Authorship Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am in file : 11253.male.26.Technology.Aquarius.xml\n",
      "I am in file : 11762.female.25.Student.Aries.xml\n",
      "I am in file : 15365.female.34.indUnk.Cancer.xml\n",
      "I am in file : 17944.female.39.indUnk.Sagittarius.xml\n",
      "I am in file : 21828.male.40.Internet.Cancer.xml\n",
      "I am in file : 23166.female.25.indUnk.Virgo.xml\n",
      "I am in file : 23191.female.23.Advertising.Taurus.xml\n",
      "I am in file : 23676.male.33.Technology.Scorpio.xml\n",
      "I am in file : 24336.male.24.Technology.Leo.xml\n",
      "I am in file : 5114.male.25.indUnk.Scorpio.xml\n",
      "I am in file : 7596.male.26.Internet.Scorpio.xml\n",
      "I am in file : 8173.male.42.indUnk.Capricorn.xml\n",
      "I am in file : 8349.male.24.Consulting.Cancer.xml\n",
      "I am in file : 9289.male.23.Marketing.Taurus.xml\n",
      "I am in file : 9470.male.25.Communications-Media.Aries.xml\n"
     ]
    }
   ],
   "source": [
    "for i in os.listdir('./Dataset/The Blog Authorship Dataset'):\n",
    "    print(\"I am in file : \" + i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XMLtoString(file):\n",
    "    with open(file) as data:\n",
    "        contents = data.read()\n",
    "        regex = re.compile(r\"&(?!amp;)\")\n",
    "        myxml = regex.sub(\"&amp;\", contents)\n",
    "    return myxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./Dataset/The Blog Authorship Dataset/11253.male.26.Technology.Aquarius.xml'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r'./Dataset/The Blog Authorship Dataset/11253.male.26.Technology.Aquarius.xml'\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = XMLtoString(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# myxml = r'<tag1>On & On &amp; On</tag1>'\n",
    "# regex = re.compile(r\"&(?!amp;|lt;|gt;)\")\n",
    "# myxml = regex.sub(\"&amp;\", myxml)\n",
    "\n",
    "# print(myxml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Blog>\n",
      "\n",
      "<date>20,July,2004</date>\n",
      "<post>\n",
      "\n",
      "     \n",
      "      About to go t bed late (again) got sucked into (another) late night film. Tonight was  urlLink Maybe Baby . It was really good made me think, but not about babies. The guy screws up his marriage and it made me think about making sure, everyday, that mine is tip top. If I'm honest there are areas that we are just getting by in - so I need to resolve to sort them out now before they are a problem. In the film they both keep diaries so I thought I should blog tonight.&amp;nbsp;   Weekend was hectic but great fun. Not that long ago k and I had to work on spending time with other people as a couple. This weekend we never ate alone, except breakfast.&amp;nbsp; K, P and I went for a very breif trip on the river saturday durring a gap in the weather. K stripped off and went for a swim, I love her so much.&amp;nbsp;   Tonight we went out for dinner. It was a lovely evening, the first in weeks, so we ate at the Bridge and sat outside, next to the  urlLink river .     \n",
      "     \n",
      "    \n",
      "</post>\n",
      "\n",
      "<date>14,July,2004</date>\n",
      "<post>\n",
      "\n",
      "     \n",
      "      My Dad has always wanted to go to  urlLink America . I have been several times, for holidays, to see friends or for work. I'd love to go with Dad and go on a long road trip. Would make a better blog than this.\n",
      "     \n",
      "    \n",
      "</post>\n",
      "\n",
      "<date>12,July,2004</date>\n",
      "<post>\n",
      "\n",
      "     \n",
      "      ...is a guy painting a blue wall blue.\n",
      "     \n",
      "    \n",
      "</post>\n",
      "\n",
      "<date>11,July,2004</date>\n",
      "<post>\n",
      "\n",
      "     \n",
      "      Can't the  urlLink weather  just sort itself out. I'm sure we'd already had 2 heat waves by this point last year. I look out of my window on yet another grey day. I wouldn't mind but this is the last free weekend I'll have in a while I want to be out enjoying it.  Yesterday we wrote some thank you cards. Kirsten worked on the garden and I bottled my latest batch of  urlLink beer . In the evening Anna and Jon came around for dinner. I made a lasagne, for the first time, and it was good fun. I'd not been feeling too great all day and was exhausted by bed time.  This morning K felt ill and stayed in bed. I was stewarding at church and as usual I was put on car parking. We(I) messed up giving out the buckets for the offering but it was ok. After church I dropped some firewood around to Liz and dropped off K's keys while I was there. Liz wasn't in but I saw paddy through the back door as I left the wood.  I don't feel that great myself. Might be time to join K in the sick bed.\n",
      "     \n",
      "    \n",
      "</post>\n",
      "\n",
      "<date>09,July,2004</date>\n",
      "<post>\n",
      "\n",
      "     \n",
      "      At last back to a normal company where it expected that you go to the pub at lunch on Fridays. Plus they have free breakfast (quite a spread too!). Good to do a bit of socialising.\n",
      "     \n",
      "    \n",
      "</post>\n",
      "\n",
      "<date>08,July,2004</date>\n",
      "<post>\n",
      "\n",
      "     \n",
      "      Induction, on Monday, was in a building right opposite the  urlLink gherkin . If I'd known I would have taken my camera. I had a bit of time to kill after getting off the train so I went for a bit of a wander around the city.  So I've been in the Cambridge office for 3 days now. The job is good and the people friendly. There is no tuckshop which will be good for my waistline but currently I'm craving snacks!  My  urlLink HDD case  arrived on Tuesday. I had a few problems at first getting it working with the aluminum case on but once I added a bit of card under the circuit board to act as insulation it worked fine. It is really small, hardly bigger than a 2.5\" drive and it works really well.  Also to arrive on Tuesday was the adoption certificate for my gibbon. NCorp  urlLink adopted  me a gibbon to remind me of them as my leaving gift. I'm sure that I have a part share in a whole troop of gibbons but I like to think there is one that's mine. I have called him Dobbo.  Andy &amp; Anita came to dinner on Tuesday night. After dinner the whole proceedings kind of deteriorated into Kirsten and Anita playing the drums while Andy tried to fix my  urlLink sparc station . Much fun was had by all.  Yesterday Labhaoise passed her driving test so K and her when to look at cars together. Pete, Labhaoise, K and I went to see  urlLink Shrek 2  in the evening which was really good.  Labhaoise was going to drive us home but then the lights in Pete's car broke (again) so he drove us back to our house. Pete and I  urlLink fixed  the lights so Labhaoise could drive the car back to their house. \n",
      "     \n",
      "    \n",
      "</post>\n",
      "\n",
      "<date>04,July,2004</date>\n",
      "<post>\n",
      "\n",
      "     \n",
      "      Welcome back. Well sort of, I discovered that my old blog from 2000 was still on the blogger.com server. I read the thirteen posts and they were really dull so I deleted the blog. It was from the days when I was living with my Dad after uni and working for Pilks. It was a month or two before I went to work in the USA which would have made a much more interesting blog had I done it.  Tomorrow I'm off to London for my induction meeting at my new company. I'm so relieved to leave NCorp that I haven't really given the new place much thought. I'm sure it will be great, I was really into the new place 3 months ago when I got the job but  urlLink the pangalactic bellwether in miserable notice periods  has kind of taken the sparkle off it a bit.  At least the train ride down will give me time to write to manda - haven't been in touch since the wedding - bad pen pal!   \n",
      "     \n",
      "    \n",
      "</post>\n",
      "\n",
      "\n",
      "</Blog>\n"
     ]
    }
   ],
   "source": [
    "regex = re.compile(r\"&(?!amp;)\")\n",
    "myxml = regex.sub(\"&amp;\", contents)\n",
    "\n",
    "print(myxml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'Blog' at 0x000001C2F27DF3B8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = et.fromstring(myxml)\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "posts = []\n",
    "for blogpost in root:\n",
    "    if(blogpost.tag == 'date'):\n",
    "        dates.append(blogpost.text)\n",
    "    if(blogpost.tag == 'post'):\n",
    "        # Converting data ot lowercase before inserting in dataframe\n",
    "        post = blogpost.text\n",
    "        post = post.lower()\n",
    "        posts.append(post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20,July,2004</td>\n",
       "      <td>\\n\\n     \\n      about to go t bed late (again...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14,July,2004</td>\n",
       "      <td>\\n\\n     \\n      my dad has always wanted to g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12,July,2004</td>\n",
       "      <td>\\n\\n     \\n      ...is a guy painting a blue w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11,July,2004</td>\n",
       "      <td>\\n\\n     \\n      can't the  urllink weather  j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09,July,2004</td>\n",
       "      <td>\\n\\n     \\n      at last back to a normal comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>08,July,2004</td>\n",
       "      <td>\\n\\n     \\n      induction, on monday, was in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>04,July,2004</td>\n",
       "      <td>\\n\\n     \\n      welcome back. well sort of, i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dates                                              posts\n",
       "0  20,July,2004  \\n\\n     \\n      about to go t bed late (again...\n",
       "1  14,July,2004  \\n\\n     \\n      my dad has always wanted to g...\n",
       "2  12,July,2004  \\n\\n     \\n      ...is a guy painting a blue w...\n",
       "3  11,July,2004  \\n\\n     \\n      can't the  urllink weather  j...\n",
       "4  09,July,2004  \\n\\n     \\n      at last back to a normal comp...\n",
       "5  08,July,2004  \\n\\n     \\n      induction, on monday, was in ...\n",
       "6  04,July,2004  \\n\\n     \\n      welcome back. well sort of, i..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['dates'] = dates\n",
    "df['posts'] = posts\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['\\n\\n     \\n      about to go t bed late (again) got sucked into (another) late night film.',\n",
       "  'tonight was  urllink maybe baby .',\n",
       "  'it was really good made me think, but not about babies.',\n",
       "  'the guy screws up his marriage and it made me think about making sure, everyday, that mine is tip top.',\n",
       "  \"if i'm honest there are areas that we are just getting by in - so i need to resolve to sort them out now before they are a problem.\",\n",
       "  'in the film they both keep diaries so i thought i should blog tonight.&nbsp;   weekend was hectic but great fun.',\n",
       "  'not that long ago k and i had to work on spending time with other people as a couple.',\n",
       "  'this weekend we never ate alone, except breakfast.&nbsp; k, p and i went for a very breif trip on the river saturday durring a gap in the weather.',\n",
       "  'k stripped off and went for a swim, i love her so much.&nbsp;   tonight we went out for dinner.',\n",
       "  'it was a lovely evening, the first in weeks, so we ate at the bridge and sat outside, next to the  urllink river .'],\n",
       " ['\\n\\n     \\n      my dad has always wanted to go to  urllink america .',\n",
       "  'i have been several times, for holidays, to see friends or for work.',\n",
       "  \"i'd love to go with dad and go on a long road trip.\",\n",
       "  'would make a better blog than this.'],\n",
       " ['\\n\\n     \\n      ...is a guy painting a blue wall blue.'],\n",
       " [\"\\n\\n     \\n      can't the  urllink weather  just sort itself out.\",\n",
       "  \"i'm sure we'd already had 2 heat waves by this point last year.\",\n",
       "  'i look out of my window on yet another grey day.',\n",
       "  \"i wouldn't mind but this is the last free weekend i'll have in a while i want to be out enjoying it.\",\n",
       "  'yesterday we wrote some thank you cards.',\n",
       "  'kirsten worked on the garden and i bottled my latest batch of  urllink beer .',\n",
       "  'in the evening anna and jon came around for dinner.',\n",
       "  'i made a lasagne, for the first time, and it was good fun.',\n",
       "  \"i'd not been feeling too great all day and was exhausted by bed time.\",\n",
       "  'this morning k felt ill and stayed in bed.',\n",
       "  'i was stewarding at church and as usual i was put on car parking.',\n",
       "  \"we(i) messed up giving out the buckets for the offering but it was ok. after church i dropped some firewood around to liz and dropped off k's keys while i was there.\",\n",
       "  \"liz wasn't in but i saw paddy through the back door as i left the wood.\",\n",
       "  \"i don't feel that great myself.\",\n",
       "  'might be time to join k in the sick bed.'],\n",
       " ['\\n\\n     \\n      at last back to a normal company where it expected that you go to the pub at lunch on fridays.',\n",
       "  'plus they have free breakfast (quite a spread too!).',\n",
       "  'good to do a bit of socialising.'],\n",
       " ['\\n\\n     \\n      induction, on monday, was in a building right opposite the  urllink gherkin .',\n",
       "  \"if i'd known i would have taken my camera.\",\n",
       "  'i had a bit of time to kill after getting off the train so i went for a bit of a wander around the city.',\n",
       "  \"so i've been in the cambridge office for 3 days now.\",\n",
       "  'the job is good and the people friendly.',\n",
       "  \"there is no tuckshop which will be good for my waistline but currently i'm craving snacks!\",\n",
       "  'my  urllink hdd case  arrived on tuesday.',\n",
       "  'i had a few problems at first getting it working with the aluminum case on but once i added a bit of card under the circuit board to act as insulation it worked fine.',\n",
       "  'it is really small, hardly bigger than a 2.5\" drive and it works really well.',\n",
       "  'also to arrive on tuesday was the adoption certificate for my gibbon.',\n",
       "  'ncorp  urllink adopted  me a gibbon to remind me of them as my leaving gift.',\n",
       "  \"i'm sure that i have a part share in a whole troop of gibbons but i like to think there is one that's mine.\",\n",
       "  'i have called him dobbo.',\n",
       "  'andy & anita came to dinner on tuesday night.',\n",
       "  'after dinner the whole proceedings kind of deteriorated into kirsten and anita playing the drums while andy tried to fix my  urllink sparc station .',\n",
       "  'much fun was had by all.',\n",
       "  'yesterday labhaoise passed her driving test so k and her when to look at cars together.',\n",
       "  'pete, labhaoise, k and i went to see  urllink shrek 2  in the evening which was really good.',\n",
       "  \"labhaoise was going to drive us home but then the lights in pete's car broke (again) so he drove us back to our house.\",\n",
       "  'pete and i  urllink fixed  the lights so labhaoise could drive the car back to their house.'],\n",
       " ['\\n\\n     \\n      welcome back.',\n",
       "  'well sort of, i discovered that my old blog from 2000 was still on the blogger.com server.',\n",
       "  'i read the thirteen posts and they were really dull so i deleted the blog.',\n",
       "  'it was from the days when i was living with my dad after uni and working for pilks.',\n",
       "  'it was a month or two before i went to work in the usa which would have made a much more interesting blog had i done it.',\n",
       "  \"tomorrow i'm off to london for my induction meeting at my new company.\",\n",
       "  \"i'm so relieved to leave ncorp that i haven't really given the new place much thought.\",\n",
       "  \"i'm sure it will be great, i was really into the new place 3 months ago when i got the job but  urllink the pangalactic bellwether in miserable notice periods  has kind of taken the sparkle off it a bit.\",\n",
       "  \"at least the train ride down will give me time to write to manda - haven't been in touch since the wedding - bad pen pal!\"]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blog_sentences = []\n",
    "for post in df['posts']:\n",
    "    sentences = sent_tokenize(post)\n",
    "    blog_sentences.append(sentences)\n",
    "df['sentence_tokenize'] = blog_sentences\n",
    "blog_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates</th>\n",
       "      <th>posts</th>\n",
       "      <th>sentence_tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20,July,2004</td>\n",
       "      <td>\\n\\n     \\n      about to go t bed late (again...</td>\n",
       "      <td>[\\n\\n     \\n      about to go t bed late (agai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14,July,2004</td>\n",
       "      <td>\\n\\n     \\n      my dad has always wanted to g...</td>\n",
       "      <td>[\\n\\n     \\n      my dad has always wanted to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12,July,2004</td>\n",
       "      <td>\\n\\n     \\n      ...is a guy painting a blue w...</td>\n",
       "      <td>[\\n\\n     \\n      ...is a guy painting a blue ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11,July,2004</td>\n",
       "      <td>\\n\\n     \\n      can't the  urllink weather  j...</td>\n",
       "      <td>[\\n\\n     \\n      can't the  urllink weather  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09,July,2004</td>\n",
       "      <td>\\n\\n     \\n      at last back to a normal comp...</td>\n",
       "      <td>[\\n\\n     \\n      at last back to a normal com...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dates                                              posts  \\\n",
       "0  20,July,2004  \\n\\n     \\n      about to go t bed late (again...   \n",
       "1  14,July,2004  \\n\\n     \\n      my dad has always wanted to g...   \n",
       "2  12,July,2004  \\n\\n     \\n      ...is a guy painting a blue w...   \n",
       "3  11,July,2004  \\n\\n     \\n      can't the  urllink weather  j...   \n",
       "4  09,July,2004  \\n\\n     \\n      at last back to a normal comp...   \n",
       "\n",
       "                                   sentence_tokenize  \n",
       "0  [\\n\\n     \\n      about to go t bed late (agai...  \n",
       "1  [\\n\\n     \\n      my dad has always wanted to ...  \n",
       "2  [\\n\\n     \\n      ...is a guy painting a blue ...  \n",
       "3  [\\n\\n     \\n      can't the  urllink weather  ...  \n",
       "4  [\\n\\n     \\n      at last back to a normal com...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving test_data to file\n",
    "# path = r'C:\\Users\\shrea\\Desktop\\Jupyter Notebooks\\IITB Internship\\IITB-ML-Assignment\\Output\\\\'\n",
    "# test_data.to_csv(path+'test_data.csv', index=False)\n",
    "# print('Saved file to disk.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['it',\n",
       "  'was',\n",
       "  'a',\n",
       "  'lovely',\n",
       "  'evening',\n",
       "  ',',\n",
       "  'the',\n",
       "  'first',\n",
       "  'in',\n",
       "  'weeks',\n",
       "  ',',\n",
       "  'so',\n",
       "  'we',\n",
       "  'ate',\n",
       "  'at',\n",
       "  'the',\n",
       "  'bridge',\n",
       "  'and',\n",
       "  'sat',\n",
       "  'outside',\n",
       "  ',',\n",
       "  'next',\n",
       "  'to',\n",
       "  'the',\n",
       "  'urllink',\n",
       "  'river',\n",
       "  '.'],\n",
       " ['would', 'make', 'a', 'better', 'blog', 'than', 'this', '.'],\n",
       " ['...', 'is', 'a', 'guy', 'painting', 'a', 'blue', 'wall', 'blue', '.'],\n",
       " ['might', 'be', 'time', 'to', 'join', 'k', 'in', 'the', 'sick', 'bed', '.'],\n",
       " ['good', 'to', 'do', 'a', 'bit', 'of', 'socialising', '.'],\n",
       " ['pete',\n",
       "  'and',\n",
       "  'i',\n",
       "  'urllink',\n",
       "  'fixed',\n",
       "  'the',\n",
       "  'lights',\n",
       "  'so',\n",
       "  'labhaoise',\n",
       "  'could',\n",
       "  'drive',\n",
       "  'the',\n",
       "  'car',\n",
       "  'back',\n",
       "  'to',\n",
       "  'their',\n",
       "  'house',\n",
       "  '.'],\n",
       " ['at',\n",
       "  'least',\n",
       "  'the',\n",
       "  'train',\n",
       "  'ride',\n",
       "  'down',\n",
       "  'will',\n",
       "  'give',\n",
       "  'me',\n",
       "  'time',\n",
       "  'to',\n",
       "  'write',\n",
       "  'to',\n",
       "  'manda',\n",
       "  '-',\n",
       "  'have',\n",
       "  \"n't\",\n",
       "  'been',\n",
       "  'in',\n",
       "  'touch',\n",
       "  'since',\n",
       "  'the',\n",
       "  'wedding',\n",
       "  '-',\n",
       "  'bad',\n",
       "  'pen',\n",
       "  'pal',\n",
       "  '!']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_lists = []\n",
    "for sentences in df['sentence_tokenize']:\n",
    "    for sentence in sentences:\n",
    "        words = word_tokenize(sentence)\n",
    "    word_lists.append(words)\n",
    "word_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates</th>\n",
       "      <th>posts</th>\n",
       "      <th>sentence_tokenize</th>\n",
       "      <th>word_tokenize</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20,July,2004</td>\n",
       "      <td>\\n\\n     \\n      about to go t bed late (again...</td>\n",
       "      <td>[\\n\\n     \\n      about to go t bed late (agai...</td>\n",
       "      <td>[it, was, a, lovely, evening, ,, the, first, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14,July,2004</td>\n",
       "      <td>\\n\\n     \\n      my dad has always wanted to g...</td>\n",
       "      <td>[\\n\\n     \\n      my dad has always wanted to ...</td>\n",
       "      <td>[would, make, a, better, blog, than, this, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12,July,2004</td>\n",
       "      <td>\\n\\n     \\n      ...is a guy painting a blue w...</td>\n",
       "      <td>[\\n\\n     \\n      ...is a guy painting a blue ...</td>\n",
       "      <td>[..., is, a, guy, painting, a, blue, wall, blu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11,July,2004</td>\n",
       "      <td>\\n\\n     \\n      can't the  urllink weather  j...</td>\n",
       "      <td>[\\n\\n     \\n      can't the  urllink weather  ...</td>\n",
       "      <td>[might, be, time, to, join, k, in, the, sick, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09,July,2004</td>\n",
       "      <td>\\n\\n     \\n      at last back to a normal comp...</td>\n",
       "      <td>[\\n\\n     \\n      at last back to a normal com...</td>\n",
       "      <td>[good, to, do, a, bit, of, socialising, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dates                                              posts  \\\n",
       "0  20,July,2004  \\n\\n     \\n      about to go t bed late (again...   \n",
       "1  14,July,2004  \\n\\n     \\n      my dad has always wanted to g...   \n",
       "2  12,July,2004  \\n\\n     \\n      ...is a guy painting a blue w...   \n",
       "3  11,July,2004  \\n\\n     \\n      can't the  urllink weather  j...   \n",
       "4  09,July,2004  \\n\\n     \\n      at last back to a normal comp...   \n",
       "\n",
       "                                   sentence_tokenize  \\\n",
       "0  [\\n\\n     \\n      about to go t bed late (agai...   \n",
       "1  [\\n\\n     \\n      my dad has always wanted to ...   \n",
       "2  [\\n\\n     \\n      ...is a guy painting a blue ...   \n",
       "3  [\\n\\n     \\n      can't the  urllink weather  ...   \n",
       "4  [\\n\\n     \\n      at last back to a normal com...   \n",
       "\n",
       "                                       word_tokenize  \n",
       "0  [it, was, a, lovely, evening, ,, the, first, i...  \n",
       "1      [would, make, a, better, blog, than, this, .]  \n",
       "2  [..., is, a, guy, painting, a, blue, wall, blu...  \n",
       "3  [might, be, time, to, join, k, in, the, sick, ...  \n",
       "4         [good, to, do, a, bit, of, socialising, .]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['word_tokenize'] = word_lists\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Saving test_data to file\n",
    "# path = r'C:\\Users\\shrea\\Desktop\\Jupyter Notebooks\\IITB Internship\\IITB-ML-Assignment\\Output\\\\'\n",
    "# test_data.to_csv(path+'test_data.csv', index=False)\n",
    "# print('Saved file to disk.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "314px",
    "left": "414px",
    "right": "20px",
    "top": "109px",
    "width": "448px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
